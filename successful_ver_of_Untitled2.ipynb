{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPcxJT+i5kUsYxnhWazyxpb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MaryamKazemit/OEBGNN/blob/main/successful_ver_of_Untitled2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(\"PyTorch version:\", torch.__version__)\n",
        "print(\"CUDA version:\", torch.version.cuda)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "orMUJkEVA5ty",
        "outputId": "50f35abe-1be7-4b06-9d18-f5890d65bcff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch version: 2.5.1+cu121\n",
            "CUDA version: 12.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch torchvision torchaudio\n",
        "# !pip install torch-geometric\n",
        "# !pip install torch-scatter torch-sparse torch-cluster torch-spline-conv\n",
        "# !pip install torch==2.0.1+cu117 torchvision==0.15.2+cu117 torchaudio==2.0.2+cu117 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "!pip install torch-geometric gensim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "xwgbPA2S47Za",
        "outputId": "9cbf4525-cf58-4816-eb3c-58ee24622abf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.20.1+cu121)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (11.0.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Collecting torch-geometric\n",
            "  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (4.3.3)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.11.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2024.10.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.26.4)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.2.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (4.66.6)\n",
            "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.13.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim) (7.0.5)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open>=1.8.1->gensim) (1.16.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (0.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.17.1)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (4.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch-geometric) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2024.8.30)\n",
            "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from multidict<7.0,>=4.5->aiohttp->torch-geometric) (4.12.2)\n",
            "Downloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m27.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch-geometric\n",
            "Successfully installed torch-geometric-2.6.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.nn import GATConv\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "from torch.optim import Adam\n",
        "import numpy as np\n",
        "from sklearn.metrics import roc_auc_score, confusion_matrix\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
        "import gc"
      ],
      "metadata": {
        "id": "MHDci4icI5Cn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yOG6UkDQ3ujx",
        "outputId": "b16e89bb-7c4e-406f-deeb-2416efbd84ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = '/content/drive/My Drive/DBLP-citation-Jan8-dataset.tar.bz2'"
      ],
      "metadata": {
        "id": "Z6t--s9g33rO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tarfile\n",
        "import os\n",
        "\n",
        "extract_path = '/content/dblp_dataset'\n",
        "with tarfile.open(file_path, 'r:bz2') as tar:\n",
        "    tar.extractall(path=extract_path)\n",
        "\n",
        "# Verify extracted files\n",
        "!ls /content/dblp_dataset"
      ],
      "metadata": {
        "id": "VCazP_Az4H6J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a761c690-f7d7-4ebb-db2b-30e2f5a80be6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DBLP-citation-Jan8.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize structures for metadata and edges\n",
        "papers = {}\n",
        "edge_index = []\n",
        "\n",
        "# Replace with the actual extracted file name\n",
        "txt_file_path = '/content/dblp_dataset/DBLP-citation-Jan8.txt'\n",
        "\n",
        "with open(txt_file_path, 'r', encoding='utf-8', errors='ignore') as file:\n",
        "    current_paper = None\n",
        "    for line in file:\n",
        "        line = line.strip()\n",
        "        if line.startswith(\"#index\"):\n",
        "            current_paper = line.replace(\"#index\", \"\").strip()\n",
        "            papers[current_paper] = {\n",
        "                \"title\": None,\n",
        "                \"authors\": [],\n",
        "                \"year\": None,\n",
        "                \"conference\": None,\n",
        "                \"abstract\": None,\n",
        "                \"citations\": []\n",
        "            }\n",
        "        elif line.startswith(\"#*\") and current_paper:\n",
        "            papers[current_paper][\"title\"] = line.replace(\"#*\", \"\").strip()\n",
        "        elif line.startswith(\"#@\") and current_paper:\n",
        "            authors = line.replace(\"#@\", \"\").strip().split(\",\")\n",
        "            papers[current_paper][\"authors\"] = [author.strip() for author in authors]\n",
        "        elif line.startswith(\"#t\") and current_paper:\n",
        "            papers[current_paper][\"year\"] = line.replace(\"#t\", \"\").strip()\n",
        "        elif line.startswith(\"#c\") and current_paper:\n",
        "            papers[current_paper][\"conference\"] = line.replace(\"#c\", \"\").strip()\n",
        "        elif line.startswith(\"#%\") and current_paper:\n",
        "            cited_paper = line.replace(\"#%\", \"\").strip()\n",
        "            papers[current_paper][\"citations\"].append(cited_paper)\n",
        "            try:\n",
        "                source = int(current_paper)\n",
        "                target = int(cited_paper)\n",
        "                edge_index.append([source, target])\n",
        "            except ValueError:\n",
        "                continue\n",
        "        elif line.startswith(\"#!\") and current_paper:\n",
        "            papers[current_paper][\"abstract\"] = line.replace(\"#!\", \"\").strip()"
      ],
      "metadata": {
        "id": "U8K9rY3y4b7n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert edge list to tensor\n",
        "if edge_index:\n",
        "    edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
        "else:\n",
        "    print(\"No edges found. Check the file format.\")"
      ],
      "metadata": {
        "id": "OG_cT4zBJiw-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "paper_ids = list(papers.keys())\n",
        "id_to_idx = {paper_id: idx for idx, paper_id in enumerate(paper_ids)}\n",
        "num_nodes = len(paper_ids)\n",
        "\n",
        "# Replace None abstracts with empty strings\n",
        "abstracts = [papers[paper_id].get(\"abstract\", \"\") or \"\" for paper_id in paper_ids]\n",
        "tagged_abstracts = [TaggedDocument(words=abstract.split(), tags=[str(i)]) for i, abstract in enumerate(abstracts)]\n",
        "doc2vec_model = Doc2Vec(tagged_abstracts, vector_size=128, window=5, min_count=1, workers=4)\n",
        "doc2vec_features = [doc2vec_model.dv[str(i)] for i in range(len(abstracts))]\n",
        "x = torch.tensor(doc2vec_features, dtype=torch.float).to(device)"
      ],
      "metadata": {
        "id": "MDsjH6ryFcIx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize labels (0: negative class, 1: positive class)\n",
        "y = torch.zeros(num_nodes, dtype=torch.long)\n",
        "\n",
        "# Set labels based on conference (e.g., 'Computer Vision' as positive class)\n",
        "for paper_id, metadata in papers.items():\n",
        "    idx = id_to_idx[paper_id]\n",
        "    conference = metadata.get(\"conference\")\n",
        "    if conference and \"Computer Vision\" in conference:\n",
        "        y[idx] = 1"
      ],
      "metadata": {
        "id": "LDM6QWvwFhld"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Update edge_index to use indices instead of paper IDs\n",
        "new_edge_index = []\n",
        "for source_id, target_id in zip(edge_index[0], edge_index[1]):\n",
        "    source = id_to_idx.get(str(source_id.item()))\n",
        "    target = id_to_idx.get(str(target_id.item()))\n",
        "    if source is not None and target is not None:\n",
        "        new_edge_index.append([source, target])\n",
        "\n",
        "# Convert to tensor\n",
        "edge_index = torch.tensor(new_edge_index, dtype=torch.long).t().contiguous()"
      ],
      "metadata": {
        "id": "2orxHWqtFlSB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "hmwI6-DOMfzZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "graph_data = Data(x=x.to(device), edge_index=edge_index.to(device), y=y.to(device))"
      ],
      "metadata": {
        "id": "fmVbEaxsFuiG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute class weights\n",
        "labels = graph_data.y.cpu().numpy()\n",
        "class_weights = compute_class_weight('balanced', classes=np.unique(labels), y=labels)\n",
        "class_weights = torch.tensor(class_weights, dtype=torch.float).to(device)"
      ],
      "metadata": {
        "id": "LLW4N-hWKkSI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ImprovedGATClassifier(nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
        "        super(ImprovedGATClassifier, self).__init__()\n",
        "        self.conv1 = GATConv(in_channels, hidden_channels, heads=8, concat=True)\n",
        "        self.conv2 = GATConv(hidden_channels * 8, hidden_channels, heads=8, concat=True)\n",
        "        self.conv3 = GATConv(hidden_channels * 8, out_channels, heads=1, concat=False)\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "        x = F.elu(self.conv1(x, edge_index))\n",
        "        x = self.dropout(x)\n",
        "        x = F.elu(self.conv2(x, edge_index))\n",
        "        x = self.dropout(x)\n",
        "        x = self.conv3(x, edge_index)\n",
        "        return F.log_softmax(x, dim=1)\n",
        "\n",
        "gnn = ImprovedGATClassifier(in_channels=x.shape[1], hidden_channels=128, out_channels=2).to(device)\n"
      ],
      "metadata": {
        "id": "4qDMbTIWKsgu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class WeightedEnsembleClassifierWithFocalLoss(nn.Module):\n",
        "    def __init__(self, gnn, gamma=2.0, class_weights=None):\n",
        "        super(WeightedEnsembleClassifierWithFocalLoss, self).__init__()\n",
        "        self.gnn = gnn\n",
        "        self.gamma = gamma\n",
        "        self.class_weights = class_weights\n",
        "\n",
        "    def forward(self, data):\n",
        "        return self.gnn(data)\n",
        "\n",
        "    def compute_loss(self, outputs, targets):\n",
        "        ce_loss = F.cross_entropy(outputs, targets, weight=self.class_weights, reduction='none')\n",
        "        pt = torch.exp(-ce_loss)\n",
        "        focal_loss = ((1 - pt) ** self.gamma * ce_loss).mean()\n",
        "        return focal_loss\n",
        "\n",
        "ensemble = WeightedEnsembleClassifierWithFocalLoss(gnn, gamma=2.0, class_weights=class_weights).to(device)\n"
      ],
      "metadata": {
        "id": "ccaoserKKwDY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, data):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        output = model(data)\n",
        "        preds = output.argmax(dim=1).cpu().numpy()\n",
        "        labels = data.y.cpu().numpy()\n",
        "        if len(np.unique(labels)) == 1 or len(np.unique(preds)) == 1:\n",
        "            g_mean = 0.0\n",
        "            roc_auc = 0.5\n",
        "        else:\n",
        "            tn, fp, fn, tp = confusion_matrix(labels, preds).ravel()\n",
        "            sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "            specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
        "            g_mean = np.sqrt(sensitivity * specificity)\n",
        "            probs = torch.exp(output)[:, 1].cpu().numpy()\n",
        "            roc_auc = roc_auc_score(labels, probs)\n",
        "        print(f'G-Mean: {g_mean:.4f}, ROC-AUC: {roc_auc:.4f}')\n",
        "        return g_mean, roc_auc"
      ],
      "metadata": {
        "id": "oGEgi2NUK33N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_with_early_stopping(model, data, optimizer, patience=5, epochs=100):\n",
        "    best_g_mean = 0\n",
        "    patience_counter = 0\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = model.compute_loss(output, data.y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        g_mean, roc_auc = evaluate_model(model, data)\n",
        "        print(f'Epoch {epoch + 1}, Loss: {loss.item():.4f}, G-Mean: {g_mean:.4f}, ROC-AUC: {roc_auc:.4f}')\n",
        "        if g_mean > best_g_mean:\n",
        "            best_g_mean = g_mean\n",
        "            patience_counter = 0\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "        if patience_counter >= patience:\n",
        "            print(\"Early stopping triggered.\")\n",
        "            break\n",
        "        torch.cuda.empty_cache()\n",
        "        gc.collect()"
      ],
      "metadata": {
        "id": "beA8ofe0K8a1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = Adam(ensemble.parameters(), lr=0.005)\n",
        "train_with_early_stopping(ensemble, graph_data, optimizer, patience=10, epochs=200)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jAFHRnGFLAqy",
        "outputId": "c6e9aaf8-98ff-4807-e936-404f558a0c83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "G-Mean: 0.0000, ROC-AUC: 0.5000\n",
            "Epoch 1, Loss: 0.6936, G-Mean: 0.0000, ROC-AUC: 0.5000\n",
            "G-Mean: 0.0008, ROC-AUC: 0.6713\n",
            "Epoch 2, Loss: 0.6823, G-Mean: 0.0008, ROC-AUC: 0.6713\n",
            "G-Mean: 0.6186, ROC-AUC: 0.6770\n",
            "Epoch 3, Loss: 0.6687, G-Mean: 0.6186, ROC-AUC: 0.6770\n",
            "G-Mean: 0.6194, ROC-AUC: 0.6839\n",
            "Epoch 4, Loss: 0.6593, G-Mean: 0.6194, ROC-AUC: 0.6839\n",
            "G-Mean: 0.6274, ROC-AUC: 0.6886\n",
            "Epoch 5, Loss: 0.6550, G-Mean: 0.6274, ROC-AUC: 0.6886\n",
            "G-Mean: 0.6384, ROC-AUC: 0.6956\n",
            "Epoch 6, Loss: 0.6499, G-Mean: 0.6384, ROC-AUC: 0.6956\n",
            "G-Mean: 0.6468, ROC-AUC: 0.7014\n",
            "Epoch 7, Loss: 0.6416, G-Mean: 0.6468, ROC-AUC: 0.7014\n",
            "G-Mean: 0.6559, ROC-AUC: 0.7081\n",
            "Epoch 8, Loss: 0.6328, G-Mean: 0.6559, ROC-AUC: 0.7081\n",
            "G-Mean: 0.6716, ROC-AUC: 0.7180\n",
            "Epoch 9, Loss: 0.6233, G-Mean: 0.6716, ROC-AUC: 0.7180\n",
            "G-Mean: 0.6890, ROC-AUC: 0.7367\n",
            "Epoch 10, Loss: 0.6130, G-Mean: 0.6890, ROC-AUC: 0.7367\n",
            "G-Mean: 0.6934, ROC-AUC: 0.7489\n",
            "Epoch 11, Loss: 0.6015, G-Mean: 0.6934, ROC-AUC: 0.7489\n",
            "G-Mean: 0.6952, ROC-AUC: 0.7521\n",
            "Epoch 12, Loss: 0.5899, G-Mean: 0.6952, ROC-AUC: 0.7521\n",
            "G-Mean: 0.6953, ROC-AUC: 0.7553\n",
            "Epoch 13, Loss: 0.5810, G-Mean: 0.6953, ROC-AUC: 0.7553\n",
            "G-Mean: 0.6932, ROC-AUC: 0.7593\n",
            "Epoch 14, Loss: 0.5717, G-Mean: 0.6932, ROC-AUC: 0.7593\n",
            "G-Mean: 0.6964, ROC-AUC: 0.7607\n",
            "Epoch 15, Loss: 0.5679, G-Mean: 0.6964, ROC-AUC: 0.7607\n",
            "G-Mean: 0.6949, ROC-AUC: 0.7627\n",
            "Epoch 16, Loss: 0.5637, G-Mean: 0.6949, ROC-AUC: 0.7627\n",
            "G-Mean: 0.6989, ROC-AUC: 0.7648\n",
            "Epoch 17, Loss: 0.5629, G-Mean: 0.6989, ROC-AUC: 0.7648\n",
            "G-Mean: 0.6990, ROC-AUC: 0.7680\n",
            "Epoch 18, Loss: 0.5616, G-Mean: 0.6990, ROC-AUC: 0.7680\n",
            "G-Mean: 0.6994, ROC-AUC: 0.7705\n",
            "Epoch 19, Loss: 0.5607, G-Mean: 0.6994, ROC-AUC: 0.7705\n",
            "G-Mean: 0.7029, ROC-AUC: 0.7737\n",
            "Epoch 20, Loss: 0.5560, G-Mean: 0.7029, ROC-AUC: 0.7737\n",
            "G-Mean: 0.7045, ROC-AUC: 0.7748\n",
            "Epoch 21, Loss: 0.5524, G-Mean: 0.7045, ROC-AUC: 0.7748\n",
            "G-Mean: 0.7024, ROC-AUC: 0.7771\n",
            "Epoch 22, Loss: 0.5466, G-Mean: 0.7024, ROC-AUC: 0.7771\n",
            "G-Mean: 0.7063, ROC-AUC: 0.7786\n",
            "Epoch 23, Loss: 0.5471, G-Mean: 0.7063, ROC-AUC: 0.7786\n",
            "G-Mean: 0.7097, ROC-AUC: 0.7797\n",
            "Epoch 24, Loss: 0.5428, G-Mean: 0.7097, ROC-AUC: 0.7797\n",
            "G-Mean: 0.7082, ROC-AUC: 0.7811\n",
            "Epoch 25, Loss: 0.5422, G-Mean: 0.7082, ROC-AUC: 0.7811\n",
            "G-Mean: 0.7098, ROC-AUC: 0.7827\n",
            "Epoch 26, Loss: 0.5412, G-Mean: 0.7098, ROC-AUC: 0.7827\n",
            "G-Mean: 0.7121, ROC-AUC: 0.7833\n",
            "Epoch 27, Loss: 0.5405, G-Mean: 0.7121, ROC-AUC: 0.7833\n",
            "G-Mean: 0.7118, ROC-AUC: 0.7846\n",
            "Epoch 28, Loss: 0.5393, G-Mean: 0.7118, ROC-AUC: 0.7846\n",
            "G-Mean: 0.7121, ROC-AUC: 0.7865\n",
            "Epoch 29, Loss: 0.5356, G-Mean: 0.7121, ROC-AUC: 0.7865\n",
            "G-Mean: 0.7125, ROC-AUC: 0.7869\n",
            "Epoch 30, Loss: 0.5351, G-Mean: 0.7125, ROC-AUC: 0.7869\n",
            "G-Mean: 0.7150, ROC-AUC: 0.7869\n",
            "Epoch 31, Loss: 0.5345, G-Mean: 0.7150, ROC-AUC: 0.7869\n",
            "G-Mean: 0.7148, ROC-AUC: 0.7882\n",
            "Epoch 32, Loss: 0.5322, G-Mean: 0.7148, ROC-AUC: 0.7882\n",
            "G-Mean: 0.7136, ROC-AUC: 0.7879\n",
            "Epoch 33, Loss: 0.5306, G-Mean: 0.7136, ROC-AUC: 0.7879\n",
            "G-Mean: 0.7168, ROC-AUC: 0.7882\n",
            "Epoch 34, Loss: 0.5288, G-Mean: 0.7168, ROC-AUC: 0.7882\n",
            "G-Mean: 0.7165, ROC-AUC: 0.7888\n",
            "Epoch 35, Loss: 0.5282, G-Mean: 0.7165, ROC-AUC: 0.7888\n",
            "G-Mean: 0.7144, ROC-AUC: 0.7893\n",
            "Epoch 36, Loss: 0.5260, G-Mean: 0.7144, ROC-AUC: 0.7893\n",
            "G-Mean: 0.7177, ROC-AUC: 0.7896\n",
            "Epoch 37, Loss: 0.5265, G-Mean: 0.7177, ROC-AUC: 0.7896\n",
            "G-Mean: 0.7171, ROC-AUC: 0.7902\n",
            "Epoch 38, Loss: 0.5256, G-Mean: 0.7171, ROC-AUC: 0.7902\n",
            "G-Mean: 0.7156, ROC-AUC: 0.7902\n",
            "Epoch 39, Loss: 0.5229, G-Mean: 0.7156, ROC-AUC: 0.7902\n",
            "G-Mean: 0.7178, ROC-AUC: 0.7914\n",
            "Epoch 40, Loss: 0.5242, G-Mean: 0.7178, ROC-AUC: 0.7914\n",
            "G-Mean: 0.7182, ROC-AUC: 0.7926\n",
            "Epoch 41, Loss: 0.5224, G-Mean: 0.7182, ROC-AUC: 0.7926\n",
            "G-Mean: 0.7170, ROC-AUC: 0.7929\n",
            "Epoch 42, Loss: 0.5222, G-Mean: 0.7170, ROC-AUC: 0.7929\n",
            "G-Mean: 0.7190, ROC-AUC: 0.7945\n",
            "Epoch 43, Loss: 0.5205, G-Mean: 0.7190, ROC-AUC: 0.7945\n",
            "G-Mean: 0.7192, ROC-AUC: 0.7950\n",
            "Epoch 44, Loss: 0.5187, G-Mean: 0.7192, ROC-AUC: 0.7950\n",
            "G-Mean: 0.7189, ROC-AUC: 0.7955\n",
            "Epoch 45, Loss: 0.5185, G-Mean: 0.7189, ROC-AUC: 0.7955\n",
            "G-Mean: 0.7204, ROC-AUC: 0.7974\n",
            "Epoch 46, Loss: 0.5187, G-Mean: 0.7204, ROC-AUC: 0.7974\n",
            "G-Mean: 0.7213, ROC-AUC: 0.7983\n",
            "Epoch 47, Loss: 0.5164, G-Mean: 0.7213, ROC-AUC: 0.7983\n",
            "G-Mean: 0.7212, ROC-AUC: 0.7992\n",
            "Epoch 48, Loss: 0.5165, G-Mean: 0.7212, ROC-AUC: 0.7992\n",
            "G-Mean: 0.7230, ROC-AUC: 0.7998\n",
            "Epoch 49, Loss: 0.5151, G-Mean: 0.7230, ROC-AUC: 0.7998\n",
            "G-Mean: 0.7245, ROC-AUC: 0.8012\n",
            "Epoch 50, Loss: 0.5136, G-Mean: 0.7245, ROC-AUC: 0.8012\n",
            "G-Mean: 0.7252, ROC-AUC: 0.8020\n",
            "Epoch 51, Loss: 0.5128, G-Mean: 0.7252, ROC-AUC: 0.8020\n",
            "G-Mean: 0.7261, ROC-AUC: 0.8025\n",
            "Epoch 52, Loss: 0.5133, G-Mean: 0.7261, ROC-AUC: 0.8025\n",
            "G-Mean: 0.7257, ROC-AUC: 0.8038\n",
            "Epoch 53, Loss: 0.5108, G-Mean: 0.7257, ROC-AUC: 0.8038\n",
            "G-Mean: 0.7253, ROC-AUC: 0.8051\n",
            "Epoch 54, Loss: 0.5099, G-Mean: 0.7253, ROC-AUC: 0.8051\n",
            "G-Mean: 0.7282, ROC-AUC: 0.8068\n",
            "Epoch 55, Loss: 0.5087, G-Mean: 0.7282, ROC-AUC: 0.8068\n",
            "G-Mean: 0.7264, ROC-AUC: 0.8076\n",
            "Epoch 56, Loss: 0.5069, G-Mean: 0.7264, ROC-AUC: 0.8076\n",
            "G-Mean: 0.7303, ROC-AUC: 0.8089\n",
            "Epoch 57, Loss: 0.5066, G-Mean: 0.7303, ROC-AUC: 0.8089\n",
            "G-Mean: 0.7271, ROC-AUC: 0.8100\n",
            "Epoch 58, Loss: 0.5049, G-Mean: 0.7271, ROC-AUC: 0.8100\n",
            "G-Mean: 0.7324, ROC-AUC: 0.8094\n",
            "Epoch 59, Loss: 0.5059, G-Mean: 0.7324, ROC-AUC: 0.8094\n",
            "G-Mean: 0.7259, ROC-AUC: 0.8107\n",
            "Epoch 60, Loss: 0.5055, G-Mean: 0.7259, ROC-AUC: 0.8107\n",
            "G-Mean: 0.7336, ROC-AUC: 0.8117\n",
            "Epoch 61, Loss: 0.5040, G-Mean: 0.7336, ROC-AUC: 0.8117\n",
            "G-Mean: 0.7329, ROC-AUC: 0.8135\n",
            "Epoch 62, Loss: 0.5019, G-Mean: 0.7329, ROC-AUC: 0.8135\n",
            "G-Mean: 0.7294, ROC-AUC: 0.8141\n",
            "Epoch 63, Loss: 0.4999, G-Mean: 0.7294, ROC-AUC: 0.8141\n",
            "G-Mean: 0.7368, ROC-AUC: 0.8134\n",
            "Epoch 64, Loss: 0.5010, G-Mean: 0.7368, ROC-AUC: 0.8134\n",
            "G-Mean: 0.7323, ROC-AUC: 0.8165\n",
            "Epoch 65, Loss: 0.5006, G-Mean: 0.7323, ROC-AUC: 0.8165\n",
            "G-Mean: 0.7327, ROC-AUC: 0.8175\n",
            "Epoch 66, Loss: 0.4974, G-Mean: 0.7327, ROC-AUC: 0.8175\n",
            "G-Mean: 0.7390, ROC-AUC: 0.8165\n",
            "Epoch 67, Loss: 0.4970, G-Mean: 0.7390, ROC-AUC: 0.8165\n",
            "G-Mean: 0.7352, ROC-AUC: 0.8185\n",
            "Epoch 68, Loss: 0.4981, G-Mean: 0.7352, ROC-AUC: 0.8185\n",
            "G-Mean: 0.7377, ROC-AUC: 0.8200\n",
            "Epoch 69, Loss: 0.4950, G-Mean: 0.7377, ROC-AUC: 0.8200\n",
            "G-Mean: 0.7414, ROC-AUC: 0.8196\n",
            "Epoch 70, Loss: 0.4929, G-Mean: 0.7414, ROC-AUC: 0.8196\n",
            "G-Mean: 0.7381, ROC-AUC: 0.8214\n",
            "Epoch 71, Loss: 0.4929, G-Mean: 0.7381, ROC-AUC: 0.8214\n",
            "G-Mean: 0.7416, ROC-AUC: 0.8222\n",
            "Epoch 72, Loss: 0.4921, G-Mean: 0.7416, ROC-AUC: 0.8222\n",
            "G-Mean: 0.7418, ROC-AUC: 0.8229\n",
            "Epoch 73, Loss: 0.4907, G-Mean: 0.7418, ROC-AUC: 0.8229\n",
            "G-Mean: 0.7415, ROC-AUC: 0.8244\n",
            "Epoch 74, Loss: 0.4901, G-Mean: 0.7415, ROC-AUC: 0.8244\n",
            "G-Mean: 0.7440, ROC-AUC: 0.8241\n",
            "Epoch 75, Loss: 0.4894, G-Mean: 0.7440, ROC-AUC: 0.8241\n",
            "G-Mean: 0.7434, ROC-AUC: 0.8258\n",
            "Epoch 76, Loss: 0.4905, G-Mean: 0.7434, ROC-AUC: 0.8258\n",
            "G-Mean: 0.7438, ROC-AUC: 0.8263\n",
            "Epoch 77, Loss: 0.4869, G-Mean: 0.7438, ROC-AUC: 0.8263\n",
            "G-Mean: 0.7447, ROC-AUC: 0.8260\n",
            "Epoch 78, Loss: 0.4888, G-Mean: 0.7447, ROC-AUC: 0.8260\n",
            "G-Mean: 0.7409, ROC-AUC: 0.8270\n",
            "Epoch 79, Loss: 0.4877, G-Mean: 0.7409, ROC-AUC: 0.8270\n",
            "G-Mean: 0.7458, ROC-AUC: 0.8256\n",
            "Epoch 80, Loss: 0.4871, G-Mean: 0.7458, ROC-AUC: 0.8256\n",
            "G-Mean: 0.7434, ROC-AUC: 0.8280\n",
            "Epoch 81, Loss: 0.4865, G-Mean: 0.7434, ROC-AUC: 0.8280\n",
            "G-Mean: 0.7456, ROC-AUC: 0.8296\n",
            "Epoch 82, Loss: 0.4840, G-Mean: 0.7456, ROC-AUC: 0.8296\n",
            "G-Mean: 0.7471, ROC-AUC: 0.8291\n",
            "Epoch 83, Loss: 0.4840, G-Mean: 0.7471, ROC-AUC: 0.8291\n",
            "G-Mean: 0.7464, ROC-AUC: 0.8312\n",
            "Epoch 84, Loss: 0.4863, G-Mean: 0.7464, ROC-AUC: 0.8312\n",
            "G-Mean: 0.7495, ROC-AUC: 0.8318\n",
            "Epoch 85, Loss: 0.4848, G-Mean: 0.7495, ROC-AUC: 0.8318\n",
            "G-Mean: 0.7489, ROC-AUC: 0.8328\n",
            "Epoch 86, Loss: 0.4791, G-Mean: 0.7489, ROC-AUC: 0.8328\n",
            "G-Mean: 0.7483, ROC-AUC: 0.8335\n",
            "Epoch 87, Loss: 0.4820, G-Mean: 0.7483, ROC-AUC: 0.8335\n",
            "G-Mean: 0.7505, ROC-AUC: 0.8338\n",
            "Epoch 88, Loss: 0.4808, G-Mean: 0.7505, ROC-AUC: 0.8338\n",
            "G-Mean: 0.7501, ROC-AUC: 0.8339\n",
            "Epoch 89, Loss: 0.4778, G-Mean: 0.7501, ROC-AUC: 0.8339\n",
            "G-Mean: 0.7515, ROC-AUC: 0.8340\n",
            "Epoch 90, Loss: 0.4778, G-Mean: 0.7515, ROC-AUC: 0.8340\n",
            "G-Mean: 0.7509, ROC-AUC: 0.8349\n",
            "Epoch 91, Loss: 0.4777, G-Mean: 0.7509, ROC-AUC: 0.8349\n",
            "G-Mean: 0.7522, ROC-AUC: 0.8354\n",
            "Epoch 92, Loss: 0.4771, G-Mean: 0.7522, ROC-AUC: 0.8354\n",
            "G-Mean: 0.7526, ROC-AUC: 0.8392\n",
            "Epoch 93, Loss: 0.4758, G-Mean: 0.7526, ROC-AUC: 0.8392\n",
            "G-Mean: 0.7520, ROC-AUC: 0.8399\n",
            "Epoch 94, Loss: 0.4744, G-Mean: 0.7520, ROC-AUC: 0.8399\n",
            "G-Mean: 0.7554, ROC-AUC: 0.8391\n",
            "Epoch 95, Loss: 0.4749, G-Mean: 0.7554, ROC-AUC: 0.8391\n",
            "G-Mean: 0.7519, ROC-AUC: 0.8412\n",
            "Epoch 96, Loss: 0.4754, G-Mean: 0.7519, ROC-AUC: 0.8412\n",
            "G-Mean: 0.7558, ROC-AUC: 0.8409\n",
            "Epoch 97, Loss: 0.4729, G-Mean: 0.7558, ROC-AUC: 0.8409\n",
            "G-Mean: 0.7546, ROC-AUC: 0.8430\n",
            "Epoch 98, Loss: 0.4731, G-Mean: 0.7546, ROC-AUC: 0.8430\n",
            "G-Mean: 0.7563, ROC-AUC: 0.8426\n",
            "Epoch 99, Loss: 0.4716, G-Mean: 0.7563, ROC-AUC: 0.8426\n",
            "G-Mean: 0.7564, ROC-AUC: 0.8428\n",
            "Epoch 100, Loss: 0.4711, G-Mean: 0.7564, ROC-AUC: 0.8428\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "g_mean, roc_auc = evaluate_model(ensemble, graph_data)\n",
        "print(f'Final G-Mean: {g_mean:.4f}, Final ROC-AUC: {roc_auc:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rrjZpwgbLET6",
        "outputId": "6119b326-c9a6-42ae-842a-ee38ad513ae6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "G-Mean: 0.7564, ROC-AUC: 0.8428\n",
            "Final G-Mean: 0.7564, Final ROC-AUC: 0.8428\n"
          ]
        }
      ]
    }
  ]
}